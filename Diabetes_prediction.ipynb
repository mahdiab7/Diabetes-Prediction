{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0H5iPK8GQSV2x5Js3Gn9N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salarMokhtariL/Diabetes-prediction/blob/main/Diabetes_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diabetes Prediction\n",
        "> Salar Mokhtari Laleh\n"
      ],
      "metadata": {
        "id": "4IDFYMa55kUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qaS_QUysAAFP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/salarMokhtariL/Diabetes-prediction/main/Data/diabetes.csv\")"
      ],
      "metadata": {
        "id": "7PJojoS6AAyP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(\"Outcome\", axis=1)\n",
        "y = data[\"Outcome\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "taZNbB87ACj3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiabetesDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X.values).float()\n",
        "        self.y = torch.tensor(y.values).unsqueeze(1).float()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = DiabetesDataset(X_train, y_train)\n",
        "test_dataset = DiabetesDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "4vyGiGztADo8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiabetesModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(8, 16)\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(16, 8)\n",
        "        self.relu2 = torch.nn.ReLU()\n",
        "        self.fc3 = torch.nn.Linear(8, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = DiabetesModel()\n"
      ],
      "metadata": {
        "id": "52dSN-ErAEft"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "ddJvE9_0AjIS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}, Training loss: {running_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0XI7FvmAkcT",
        "outputId": "7b53f56e-16a9-40a9-d8f1-2e34114da8f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 0.9570\n",
            "Epoch 2, Training loss: 0.6550\n",
            "Epoch 3, Training loss: 0.6438\n",
            "Epoch 4, Training loss: 0.6376\n",
            "Epoch 5, Training loss: 0.6181\n",
            "Epoch 6, Training loss: 0.6234\n",
            "Epoch 7, Training loss: 0.6002\n",
            "Epoch 8, Training loss: 0.6111\n",
            "Epoch 9, Training loss: 0.5951\n",
            "Epoch 10, Training loss: 0.5949\n",
            "Epoch 11, Training loss: 0.5929\n",
            "Epoch 12, Training loss: 0.5871\n",
            "Epoch 13, Training loss: 0.5923\n",
            "Epoch 14, Training loss: 0.5843\n",
            "Epoch 15, Training loss: 0.5916\n",
            "Epoch 16, Training loss: 0.5709\n",
            "Epoch 17, Training loss: 0.5919\n",
            "Epoch 18, Training loss: 0.5807\n",
            "Epoch 19, Training loss: 0.5731\n",
            "Epoch 20, Training loss: 0.5670\n",
            "Epoch 21, Training loss: 0.5716\n",
            "Epoch 22, Training loss: 0.5805\n",
            "Epoch 23, Training loss: 0.5601\n",
            "Epoch 24, Training loss: 0.5842\n",
            "Epoch 25, Training loss: 0.5676\n",
            "Epoch 26, Training loss: 0.5744\n",
            "Epoch 27, Training loss: 0.5639\n",
            "Epoch 28, Training loss: 0.5664\n",
            "Epoch 29, Training loss: 0.5694\n",
            "Epoch 30, Training loss: 0.5616\n",
            "Epoch 31, Training loss: 0.5561\n",
            "Epoch 32, Training loss: 0.5814\n",
            "Epoch 33, Training loss: 0.5655\n",
            "Epoch 34, Training loss: 0.5624\n",
            "Epoch 35, Training loss: 0.5545\n",
            "Epoch 36, Training loss: 0.5562\n",
            "Epoch 37, Training loss: 0.5645\n",
            "Epoch 38, Training loss: 0.5614\n",
            "Epoch 39, Training loss: 0.5554\n",
            "Epoch 40, Training loss: 0.5464\n",
            "Epoch 41, Training loss: 0.5486\n",
            "Epoch 42, Training loss: 0.5469\n",
            "Epoch 43, Training loss: 0.5517\n",
            "Epoch 44, Training loss: 0.5579\n",
            "Epoch 45, Training loss: 0.5529\n",
            "Epoch 46, Training loss: 0.5544\n",
            "Epoch 47, Training loss: 0.5460\n",
            "Epoch 48, Training loss: 0.5450\n",
            "Epoch 49, Training loss: 0.5370\n",
            "Epoch 50, Training loss: 0.5408\n",
            "Epoch 51, Training loss: 0.5395\n",
            "Epoch 52, Training loss: 0.5502\n",
            "Epoch 53, Training loss: 0.5425\n",
            "Epoch 54, Training loss: 0.5546\n",
            "Epoch 55, Training loss: 0.5351\n",
            "Epoch 56, Training loss: 0.5426\n",
            "Epoch 57, Training loss: 0.5442\n",
            "Epoch 58, Training loss: 0.5353\n",
            "Epoch 59, Training loss: 0.5309\n",
            "Epoch 60, Training loss: 0.5529\n",
            "Epoch 61, Training loss: 0.5368\n",
            "Epoch 62, Training loss: 0.5417\n",
            "Epoch 63, Training loss: 0.5393\n",
            "Epoch 64, Training loss: 0.5358\n",
            "Epoch 65, Training loss: 0.5390\n",
            "Epoch 66, Training loss: 0.5328\n",
            "Epoch 67, Training loss: 0.5359\n",
            "Epoch 68, Training loss: 0.5316\n",
            "Epoch 69, Training loss: 0.5216\n",
            "Epoch 70, Training loss: 0.5211\n",
            "Epoch 71, Training loss: 0.5239\n",
            "Epoch 72, Training loss: 0.5283\n",
            "Epoch 73, Training loss: 0.5223\n",
            "Epoch 74, Training loss: 0.5272\n",
            "Epoch 75, Training loss: 0.5277\n",
            "Epoch 76, Training loss: 0.5151\n",
            "Epoch 77, Training loss: 0.5184\n",
            "Epoch 78, Training loss: 0.5136\n",
            "Epoch 79, Training loss: 0.5175\n",
            "Epoch 80, Training loss: 0.5122\n",
            "Epoch 81, Training loss: 0.5214\n",
            "Epoch 82, Training loss: 0.5273\n",
            "Epoch 83, Training loss: 0.5182\n",
            "Epoch 84, Training loss: 0.5268\n",
            "Epoch 85, Training loss: 0.5340\n",
            "Epoch 86, Training loss: 0.5264\n",
            "Epoch 87, Training loss: 0.5243\n",
            "Epoch 88, Training loss: 0.5151\n",
            "Epoch 89, Training loss: 0.5043\n",
            "Epoch 90, Training loss: 0.5174\n",
            "Epoch 91, Training loss: 0.5038\n",
            "Epoch 92, Training loss: 0.5126\n",
            "Epoch 93, Training loss: 0.5129\n",
            "Epoch 94, Training loss: 0.5146\n",
            "Epoch 95, Training loss: 0.5110\n",
            "Epoch 96, Training loss: 0.5029\n",
            "Epoch 97, Training loss: 0.5084\n",
            "Epoch 98, Training loss: 0.5051\n",
            "Epoch 99, Training loss: 0.5237\n",
            "Epoch 100, Training loss: 0.5098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}, Training loss: {running_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qK2pFQyAl2i",
        "outputId": "bceb660e-a948-4830-866b-c92483dba930"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 0.5046\n",
            "Epoch 2, Training loss: 0.5126\n",
            "Epoch 3, Training loss: 0.4986\n",
            "Epoch 4, Training loss: 0.5049\n",
            "Epoch 5, Training loss: 0.4917\n",
            "Epoch 6, Training loss: 0.5064\n",
            "Epoch 7, Training loss: 0.5073\n",
            "Epoch 8, Training loss: 0.5094\n",
            "Epoch 9, Training loss: 0.4937\n",
            "Epoch 10, Training loss: 0.4959\n",
            "Epoch 11, Training loss: 0.4973\n",
            "Epoch 12, Training loss: 0.5066\n",
            "Epoch 13, Training loss: 0.4986\n",
            "Epoch 14, Training loss: 0.5009\n",
            "Epoch 15, Training loss: 0.4965\n",
            "Epoch 16, Training loss: 0.4958\n",
            "Epoch 17, Training loss: 0.4959\n",
            "Epoch 18, Training loss: 0.4992\n",
            "Epoch 19, Training loss: 0.4846\n",
            "Epoch 20, Training loss: 0.5042\n",
            "Epoch 21, Training loss: 0.4979\n",
            "Epoch 22, Training loss: 0.4848\n",
            "Epoch 23, Training loss: 0.4987\n",
            "Epoch 24, Training loss: 0.5079\n",
            "Epoch 25, Training loss: 0.5056\n",
            "Epoch 26, Training loss: 0.4914\n",
            "Epoch 27, Training loss: 0.4910\n",
            "Epoch 28, Training loss: 0.4838\n",
            "Epoch 29, Training loss: 0.4877\n",
            "Epoch 30, Training loss: 0.4852\n",
            "Epoch 31, Training loss: 0.4893\n",
            "Epoch 32, Training loss: 0.4794\n",
            "Epoch 33, Training loss: 0.4953\n",
            "Epoch 34, Training loss: 0.4936\n",
            "Epoch 35, Training loss: 0.4848\n",
            "Epoch 36, Training loss: 0.4714\n",
            "Epoch 37, Training loss: 0.4880\n",
            "Epoch 38, Training loss: 0.4884\n",
            "Epoch 39, Training loss: 0.4736\n",
            "Epoch 40, Training loss: 0.4855\n",
            "Epoch 41, Training loss: 0.4782\n",
            "Epoch 42, Training loss: 0.4900\n",
            "Epoch 43, Training loss: 0.4998\n",
            "Epoch 44, Training loss: 0.4809\n",
            "Epoch 45, Training loss: 0.4689\n",
            "Epoch 46, Training loss: 0.4875\n",
            "Epoch 47, Training loss: 0.4838\n",
            "Epoch 48, Training loss: 0.4692\n",
            "Epoch 49, Training loss: 0.4680\n",
            "Epoch 50, Training loss: 0.4731\n",
            "Epoch 51, Training loss: 0.4883\n",
            "Epoch 52, Training loss: 0.4721\n",
            "Epoch 53, Training loss: 0.4701\n",
            "Epoch 54, Training loss: 0.4628\n",
            "Epoch 55, Training loss: 0.4772\n",
            "Epoch 56, Training loss: 0.4791\n",
            "Epoch 57, Training loss: 0.4626\n",
            "Epoch 58, Training loss: 0.4909\n",
            "Epoch 59, Training loss: 0.4809\n",
            "Epoch 60, Training loss: 0.4562\n",
            "Epoch 61, Training loss: 0.4666\n",
            "Epoch 62, Training loss: 0.4670\n",
            "Epoch 63, Training loss: 0.4788\n",
            "Epoch 64, Training loss: 0.4632\n",
            "Epoch 65, Training loss: 0.4613\n",
            "Epoch 66, Training loss: 0.4750\n",
            "Epoch 67, Training loss: 0.4678\n",
            "Epoch 68, Training loss: 0.4657\n",
            "Epoch 69, Training loss: 0.4656\n",
            "Epoch 70, Training loss: 0.4661\n",
            "Epoch 71, Training loss: 0.4599\n",
            "Epoch 72, Training loss: 0.4552\n",
            "Epoch 73, Training loss: 0.4578\n",
            "Epoch 74, Training loss: 0.4489\n",
            "Epoch 75, Training loss: 0.4532\n",
            "Epoch 76, Training loss: 0.4559\n",
            "Epoch 77, Training loss: 0.4759\n",
            "Epoch 78, Training loss: 0.4620\n",
            "Epoch 79, Training loss: 0.4589\n",
            "Epoch 80, Training loss: 0.4540\n",
            "Epoch 81, Training loss: 0.4703\n",
            "Epoch 82, Training loss: 0.4771\n",
            "Epoch 83, Training loss: 0.4648\n",
            "Epoch 84, Training loss: 0.4514\n",
            "Epoch 85, Training loss: 0.4482\n",
            "Epoch 86, Training loss: 0.4486\n",
            "Epoch 87, Training loss: 0.4551\n",
            "Epoch 88, Training loss: 0.4483\n",
            "Epoch 89, Training loss: 0.4498\n",
            "Epoch 90, Training loss: 0.4737\n",
            "Epoch 91, Training loss: 0.4505\n",
            "Epoch 92, Training loss: 0.4461\n",
            "Epoch 93, Training loss: 0.4500\n",
            "Epoch 94, Training loss: 0.4532\n",
            "Epoch 95, Training loss: 0.4461\n",
            "Epoch 96, Training loss: 0.4454\n",
            "Epoch 97, Training loss: 0.4438\n",
            "Epoch 98, Training loss: 0.4569\n",
            "Epoch 99, Training loss: 0.4468\n",
            "Epoch 100, Training loss: 0.4455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        predicted = torch.round(torch.sigmoid(outputs))\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    accuracy = correct/total\n",
        "    print(f\"Test accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifMrGjFWAptA",
        "outputId": "2d0c312f-c2e3-4e7d-c504-3a737ee237ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b3VTVADyAwHg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}